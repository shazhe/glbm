---
title: "Estimating GIA -- 4 Pseudo polygon with mixture Gaussian"
author: "Z Sha"
date: "13 November 2017"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

# Introduction

In this document, we apply the pseudo polygon within mixture Gaussian model on GIA. The idea is that GIA is a stationary porcess on a subset of $S^2$. The subset is given by removing polygons where the values are certainly zero according to experts from the entire sphere. In previous experiments, we have done a global stationary model, pseudo polygons with point observations at the polygon boundaries. In this document, we use a single pseudo polygon observation to update the process. 

We generate dense mesh in the subset and sparse mesh insise the pseudo polygons. Pseudo observations are placed sparsely incide the polygons and along the bouondaries. The correlations length of the pseudo polygons are set to be larege. Why?

(1) process inside these polygons are uniformly zero. So either they are strongly correlated or they are independent but having tiny variance.

(2) we want a sparse mesh for these regions and to have a good approximation requires longer correlation length.

## 1 Generate the polygons and mesh
First we generate the mesh for a discreate reparesentation of the GIA process. The mesh is restricted on a subset of the sphere defined by the pseudo-polygons. More details about choosing and generating the polygons can be found [here](http://rpubs.com/zs_sz/PseudoObs02). The following chunk generate the pseudo polygons using the ensemble mean of 13 GIA mode solutions for a given threshold value, say $0.3$.

```{r load, message = FALSE}
## load library and functions
library(INLA)
library(sp); library(GEOmap); library(rgdal)
library(ggplot2); library(grid); library(gridExtra)
source("functions.R")
source("functions-barriers-dt-models-march2017.R")
```

```{r polygons, include = FALSE, message = FALSE, cache = TRUE}
## Load the pseudo polygon
#### 1 Load GIA prior
if(Sys.info()["sysname"] == "Windows"){
  zeroPolygon <- readOGR(dsn = "Z:/WP1-BHM/Experiment1b/shapefiles", layer = "zero03")
}else if(grep("Ubuntu",Sys.info()["version"]) == 1){
  zeroPolygon <- readOGR(dsn = "/home/zs16444/GMdata/shapefiles", layer = "zero03")
}else{
  zeroPolygon <- readOGR(dsn = "/./projects/GlobalMass/WP1-BHM/Experiment1b/shapefiles", layer = "zero03")
}
## Remove polygons that are too small
zeroPolys <- zeroPolygon@polygons[[1]]@Polygons
polyareas <- sapply(zeroPolys, function(x) x@area)
polyholes <- sapply(zeroPolys, function(x) x@hole)

zeropolys2 <- zeroPolys[polyareas > 200 ] 
zeroPoly <- zeroPolygon
zeroPoly@polygons[[1]]@Polygons <- zeropolys2
```

Next we generate the mesh and separate the triangles in/out-side of the polygons. 
```{r mesh, include=TRUE, cache=TRUE}
#### Dense points outside polygons
fibo_points <- fiboSphere(N = 12960, L0 = TRUE)
pinPoly <- unlist(over(zeroPoly, SpatialPoints(coords = fibo_points), returnList=T))
fibo_inSub<- fibo_points[-pinPoly,]
plot(zeroPoly)
points(fibo_inSub, pch = ".")

#### Sparse points in the polygons
fibo_points <- fiboSphere(N = 500, L0=TRUE)
pinPoly <- unlist(over(zeroPoly, SpatialPoints(coords = fibo_points), returnList=T))
fibo_inPoly<- fibo_points[pinPoly,]
plot(zeroPoly)
points(fibo_inPoly, pch = ".")
points(fibo_inSub, pch = ".")

fibo_points_all <- rbind(fibo_inPoly, fibo_inSub)
mesh_points_xyz <- do.call(cbind, Lll2xyz(lat = fibo_points_all[,2], lon = fibo_points_all[,1]))
mesh <- inla.mesh.2d(loc = mesh_points_xyz, cutoff = 0.01, max.edge = 0.5)
summary(mesh) # give the desired number of vertices and triangles.
```


Now separate the triangles by the pseudo-polygons.
```{r mesh2, include = TRUE, cache=TRUE}
mesh <- dt.mesh.addon.posTri(mesh = mesh, globe = TRUE)
Tlonlat <- Lxyz2ll(list(x = mesh$posTri[,1], y = mesh$posTri[,2], z = mesh$posTri[,3]))
Tlonlat$lon <- ifelse(Tlonlat$lon >=0, Tlonlat$lon, Tlonlat$lon + 359)
mesh$Trill <- cbind(lon = Tlonlat$lon, lat =Tlonlat$lat)
TinPoly <- unlist(over(zeroPoly, SpatialPoints(coords=mesh$Trill), returnList=T))
TAll <- 1:mesh$t
ToutPoly <- TAll[-TinPoly]
Omega = dt.Omega(list(TinPoly, 1:mesh$t), mesh)
plot(mesh, t.sub = Omega[[2]])
plot(mesh, t.sub = Omega[[1]])
```



## 2 Data preparation

## 2.1 GIA forward model solution
Load the GIA prior mean and GPS data and do the same prepreation as previous.
```{r load_data0, include=FALSE, eval = TRUE, cache = TRUE}
#### 1 Load GIA prior
if(Sys.info()["sysname"] == "Windows"){
  ice6g <- read.table("Z:/WP2-SolidEarth/BHMinputs/GIA/GIA_Pel-6-VM5.txt", header = T)
}else if(grep("Ubuntu",Sys.info()["version"]) == 1){
  ice6g <- read.table("~/GMdata/BHMinputs/GIA/GIA_Pel-6-VM5.txt", header = T)
}else{
  ice6g <- read.table("/./projects/GlobalMass/WP2-SolidEarth/BHMinputs/GIA/GIA_Pel-6-VM5.txt", header = T)
}

polycoords <- ice6g[,c(6:13, 6,7)] 
plist <- lapply(ice6g$ID, 
                function(x) Polygons(list(Polygon(cbind(lon = as.numeric(polycoords[x, c(1,3,5,7,9)]), 
                                                        lat = as.numeric(polycoords[x, c(2,4,6,8,10)])))), ID = x))
Plist <- SpatialPolygons(plist, proj4string = CRS("+proj=longlat"))

meshLL <- Lxyz2ll(list(x=mesh$loc[,1], y = mesh$loc[,2], z = mesh$loc[,3]))
meshLL$lon <- ifelse(meshLL$lon >= -0.5, meshLL$lon,meshLL$lon + 360)
mesh_sp <- SpatialPoints(data.frame(lon = meshLL$lon, lat = meshLL$lat), proj4string = CRS("+proj=longlat")) 
mesh_idx <- over(mesh_sp, Plist)
GIA_prior <- ice6g$trend[mesh_idx]

#### 2 Load GPS data
if(Sys.info()["sysname"] == "Windows"){
  GPSV4b <- read.table("Z:/WP2-SolidEarth/BHMinputs/GPS/GPS_v04b.txt", header = T)
}else if(grep("Ubuntu",Sys.info()["version"]) == 1){
  GPSV4b <- read.table("~/GMdata/BHMinputs/GPS/GPS_v04b.txt", header = T)
}else{
  GPSV4b <- read.table("/./projects/GlobalMass/WP2-SolidEarth/BHMinputs/GPS/GPS_v04b.txt", header = T)
}
```


## GPS data

Remove GPS data inside the pseudo-polygons.
```{r data, include = TRUE, cache=TRUE}
GPS_inPoly <- unlist(over(zeroPoly, SpatialPoints(coords = cbind(GPSV4b$lon, GPSV4b$lat)), returnList=T))
GPS_All <- 1:nrow(GPSV4b)
GPS_outPoly <- GPS_All[-GPS_inPoly]
plot(GPSV4b[GPS_outPoly,c("lon", "lat")], pch = "+")

GPS_data <- GPSV4b[GPS_outPoly,]
GPS_loc <- do.call(cbind, Lll2xyz(lat = GPS_data$lat, lon = GPS_data$lon))
GPS_sp <- SpatialPoints(data.frame(lon = ifelse(GPS_data$lon>359.5, GPS_data$lon - 360, GPS_data$lon), 
                                   lat = GPS_data$lat), proj4string = CRS("+proj=longlat"))

GPS_idx <- over(GPS_sp, Plist)
GPS_mu <- ice6g$trend[GPS_idx]
GPS_data$trend0 <- GPS_data$trend - GPS_mu
```

We also add some pseudo observations along the boudaries of the polygons to make smooth transition of the predictions and the mesh nodes incide the polygons. These values are set to be the ice6 values at those locations with opposite signs.
```{r data2, include = TRUE, cache=TRUE}
## get the boundary of the polygons
boundlines <- as(zeroPoly, 'SpatialLines') 
obs_bounds <- spsample(boundlines, n = 50, type = "regular") # note points more than specified
## The mesh nodes incide the polygons
Vll <- Lxyz2ll(list(x = mesh$loc[,1], y = mesh$loc[,2], z = mesh$loc[,3]))
Vll$lon <- ifelse(Vll$lon < 0, Vll$lon + 360, Vll$lon)
Vll <- cbind(Vll$lon, Vll$lat)
VinPoly <- unlist(over(zeroPoly, SpatialPoints(coords=Vll), returnList=T))


obs_inpoly <- spsample(zeroPoly, n = 3000, type = "regular")
obs_pseudo <-  obs_inpoly
proj4string(obs_pseudo) <- proj4string(Plist)

## Find the ice6g values
pobs_idx <- over(obs_pseudo, Plist)
GIA_pobs <- ice6g$trend[pobs_idx]

nobsb <-nrow(obs_pseudo@coords)
obs_df <- data.frame(ID = rep("pseudo", nobsb), lon = obs_pseudo@coords[,1], lat = obs_pseudo@coords[,2],
                     trend = rep(0, nobsb), std = rep(0.1, nobsb), trend0 = -GIA_pobs)
obs_xyz <- do.call(cbind, Lll2xyz(lat = obs_pseudo@coords[,2], lon = obs_pseudo@coords[,1]))

GPS_all <- rbind(GPS_data, obs_df)
GPS_all_loc <- rbind(GPS_loc, obs_xyz)
```



## 3 Inference on the subset

First set up the data, prediction stacks and the GPS prior as before.
```{r inla, include = TRUE, cache = TRUE}
Mesh_GIA <- mesh
A_data <- inla.spde.make.A(mesh = Mesh_GIA, loc = GPS_all_loc)
A_pred <- inla.spde.make.A(mesh = Mesh_GIA, loc = rbind(GPS_all_loc, Mesh_GIA$loc))

## Create the estimation and prediction stack
st.est <- inla.stack(data = list(y=GPS_all$trend0), A = list(A_data),
                     effects = list(GIA = 1:Mesh_GIA$n), tag = "est")
st.pred <- inla.stack(data = list(y=NA), A = list(A_pred),
                      effects = list(GIA=1:Mesh_GIA$n), tag = "pred")
stGIA <- inla.stack(st.est, st.pred)

## Fix the GPS errors
hyper <- list(prec = list(fixed = TRUE, initial = 0))
prec_scale <- c(1/GPS_all$std^2, rep(1, nrow(A_pred)))
```

### Set up prior and build Q

This part is ***different***. We set up the priors for the hyper-parameters and there are a few options we can compare. We have chosen to use the log-normal distribution for $\sigma$ and $\rho$ for the other models and in this model we keep them the same. 
```{r prior1, include=TRUE, cache=TRUE}
mu_r <- 500/6371
v_r <- (1000/6371)^2
mu_s <- 20
v_s <- 40^2

## Transform the parameters for the SPDE_GMRF approximation
Tlognorm <- function(mu, v){
  logv <- log(1 + v/mu^2)
  logmu <- log(mu^2) - 0.5*log(mu^2 + v)
  return(c(logmu, logv))
}
trho <- Tlognorm(mu_r, v_r)
tsigma <- Tlognorm(mu_s, v_s)
```

For the zero region, we also need to set up the priors. We can either fix the hyper-parameters to be some value or also set priors on them. We consider the following senarios for the zero region

(1) fix $\rho_0$ and $\sigma_0$ and $\sigma_0 = \sigma$

(2) fix $\rho_0$ and $\sigma_0$ and $\sigma_0 \neq \sigma$.

(3) vary $\rho_0$ and $\sigma_0 = \sigma$.

(4) vary $\rho_0$ and fix $\sigma_0 \neq \sigma$.

(5) vary both $\rho_0$ and $\sigma_0$.

```{r prior2, include=TRUE, cache=TRUE}
## Senario 1
Q.mixture = dt.create.Q(mesh, Omega, fixed.ranges = c(5, NA))
prior <- list(sigma = tsigma, range = matrix(trho, ncol = 2))
log.prior <- dt.create.prior.log.norm(prior.param = prior0) 
GIA_spde1 = dt.inla.model(Q = Q.mixture, log.prior=log.prior)

## Senario 2
Q.mixture = dt.create.Q(mesh, Omega, fixed.ranges = c(0.01, NA), same_sigma = FALSE, fixed.sigmas = c(0.1, NA))
prior <- list(sigma = tsigma, range = matrix(trho, ncol = 2))
log.prior <- dt.create.prior.log.norm(prior.param = prior0) 
GIA_spde1 = dt.inla.model(Q = Q.mixture, log.prior=log.prior)

## Senario 3
Q.mixture = dt.create.Q(mesh, Omega, sam_sigma = TRUE)
trho0 <- Tlognorm(50/6371, (100/6371)^2)
prior <- list(sigma = tsigma, range = rbind(trho0, trho) )
log.prior <- dt.create.prior.log.norm(prior.param = prior) 
GIA_spde3 = dt.inla.model(Q = Q.mixture, log.prior=log.prior)

## Senario 4
Q.mixture = dt.create.Q(mesh, Omega, fixed.ranges = c(0.01, NA))
prior <- list(sigma = tsigma, range = matrix(trho, ncol = 2))
log.prior <- dt.create.prior.log.norm(prior.param = prior0) 
GIA_spde1 = dt.inla.model(Q = Q.mixture, log.prior=log.prior)

## senario 5
Q.mixture = dt.create.Q(mesh, Omega, fixed.ranges = c(0.01, NA))
prior <- list(sigma = tsigma, range = matrix(trho, ncol = 2))
log.prior <- dt.create.prior.log.norm(prior.param = prior0) 
GIA_spde1 = dt.inla.model(Q = Q.mixture, log.prior=log.prior)

tsigma0 <- Tlognorm(0.2, 0.4^2)
Q.mixture = dt.create.Q(mesh, Omega)
mu_r0 <-50/6371
v_r0 <- (100/6371)
trho0 <- Tlognorm(mu_r0, v_r0)


# prior.param$sigma[1] = E(theta[1]), prior.param$sigma[2] = V(theta[1])
# prior.param$range[1,1] = E(theta[2), prior.param$sigma[1,2] = V(theta[2]),...


log.prior <- dt.create.prior.log.norm(prior.param = prior0) 
# - The prior parameters are the lambdas in the exponential 
#   priors for standard deviation and inverse-range
```

```{r spde_mod}


formula <- y ~ -1 + f(GIA, model=GIA_spde1)
# - The spatial model component is different from before
# - The rest of the model setup is the same! 
#   (as in the stationary case)
# - - e.g. the inla(...) call below is the same, 
#     only this formula is different
```

Then we run the INLA model. Note that this will take more than 10min and require memory larger than 32GB. We ran this on a server with 56 cores and 256GB memory.
```{r run_inla, include = TRUE, eval = FALSE}
res_inla <- inla(formula, data=inla.stack.data(stGIA), family = "gaussian",
                   scale =prec_scale, control.family = list(hyper = hyper),
                   control.predictor=list(A = inla.stack.A(stGIA), compute = TRUE))

```

```{r inla_load, include = FALSE, eval = TRUE}
#save(res_inla, file = "/./projects/GlobalMass/WP1-BHM/Experiment1b/GIA_RGL/res4.RData")

if(Sys.info()["sysname"] == "Windows"){
  load("Z:/WP1-BHM/Experiment1b/GIA_RGL/res4.RData")
}else if(grep("Ubuntu",Sys.info()["version"]) == 1){
 load("~/GMdata/GIA_RGL/res4.RData")
}
INLA_pred <- res_inla$summary.linear.predictor
```

# Analyse results

Now assemble the inla inference and prediction results.

```{r inla_res, include = TRUE, cache=TRUE}
## Extract and project predictions
INLA_pred <- res_inla$summary.linear.predictor
pred_idx <- inla.stack.index(stGIA, tag = "pred")$data
GPS_idx <- pred_idx[1:nrow(GPS_all)]
GIA_idx <- pred_idx[-c(1:nrow(GPS_all))]

## GPS 
GPS_u <- INLA_pred$sd[GPS_idx] 
GPS_pred <- data.frame(lon = GPS_all$lon, lat = GPS_all$lat, u = GPS_u)

## GIA
GIA_diff <- INLA_pred$mean[GIA_idx] 
GIA_m <- GIA_diff + GIA_prior
GIA_u <- INLA_pred$sd[GIA_idx]
proj <- inla.mesh.projector(Mesh_GIA, projection = "longlat", dims = c(360,180), xlim = c(0,360), ylim = c(-90, 90))
GIA_grid <- expand.grid(proj$x, proj$y)
GIA_pred <- data.frame(lon = GIA_grid[,1], lat = GIA_grid[,2],
                       diff = as.vector(inla.mesh.project(proj, as.vector(GIA_diff))),
                       mean = as.vector(inla.mesh.project(proj, as.vector(GIA_m))),
                       u = as.vector(inla.mesh.project(proj, as.vector(GIA_u))))

ress <- list(res_inla = res_inla, spde = GIA_spde1, st = stGIA, 
             mesh = Mesh_GIA, GPS_pred = GPS_pred, GIA_pred = GIA_pred)
```


## Plot the posteriors of the hyper parameters

```{r hyper, include=TRUE}
theta1 <- res_inla$marginals.hyperpar$`Theta1 for GIA`
theta2 <- res_inla$marginals.hyperpar$`Theta2 for GIA`
theta3 <- res_inla$marginals.hyperpar$`Theta3 for GIA`

Vmar<- inla.tmarginal(exp, theta1)
Rmar1 <- inla.tmarginal(exp, theta2)
Rmar2 <- inla.tmarginal(exp, theta3)

## Find the mode of rho and sigma^2
lrho_mode <- res_inla$summary.hyperpar$mode[2]
lrho_mean <- res_inla$summary.hyperpar$mean[2]
lrho_sd <- res_inla$summary.hyperpar$sd[2]
rho_mode <- exp(lrho_mean - lrho_sd^2)

lrho_mode2 <- res_inla$summary.hyperpar$mode[3]
lrho_mean2 <- res_inla$summary.hyperpar$mean[3]
lrho_sd2 <- res_inla$summary.hyperpar$sd[3]
rho_mode2 <- exp(lrho_mean2 - lrho_sd2^2)

lsigma_mode <- res_inla$summary.hyperpar$mode[1]
lsigma_mean <- res_inla$summary.hyperpar$mean[1]
lsigma_sd <- res_inla$summary.hyperpar$sd[1]
sigma_mode <- exp(lsigma_mean - lsigma_sd^2)

plot(Vmar, type = "l", main = bquote(bold({sigma^2}("mode") == .(round(sigma_mode, 4)))))
plot(Rmar1, type = "l", main = bquote(bold(rho("mode") == .(round(rho_mode, 4)))))
plot(Rmar2, type = "l", main = bquote(bold(rho("mode") == .(round(rho_mode2, 4)))))
## The estimated correlation length is about 568km
rho_mode*6371
```


## Plot the predictions

```{r predict, include=TRUE}
GPS_pred <- ress$GPS_pred
GIA_pred <- ress$GIA_pred

map_prior <- map_res(data = ice6g, xname = "x_center", yname = "y_center", fillvar = "trend", 
                      limits = c(-7, 22), title = "Prior GIA mean field")

## Plot the GIA predicted mean
map_GIA <- map_res(data = GIA_pred, xname = "lon", yname = "lat", fillvar = "mean", 
                   limits = c(-7, 22), title = "Predicted GIA")

## Plot the GIA difference map
map_diff <- map_res(data = GIA_pred, xname = "lon", yname = "lat", fillvar = "diff", 
                   limits = c(-8, 8), title = "GIA difference: Updated - Prior")

## Plot the GIA difference map
map_sd <- map_res(data = GIA_pred, xname = "lon", yname = "lat", fillvar = "u", 
                    colpal = colorRamps::matlab.like(12),  title = "Predicted uncertainties")

## Display 
print(map_prior)
print(map_GIA)
print(map_diff)
print(map_sd)
```