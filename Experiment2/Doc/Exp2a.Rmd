---
title: "Experiment 2a"
author: "Z Sha"
date: "22 November 2017"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

In this experiment, we assume the GIA is knonw so there will be only two independent latent process $X_{ssh}$ and $X_{mass}$ and the thrid one $X_{steric}$ is given by $X_{steric} = X_{ssh} - x_{GIA} - X_{mass}$. Given the altimetry and GRACE data, the $X_{steric}$ can be predicted as an linear combination of posterior ssh and mass change:
$$X_{steric} |  Y_{alt}, Y_{GRACE} = X_{ssh} | Y_{alt} - X_{mass}|Y_{GRACE} - x_{GIA}$$

Therefore, in the following we use the same approach as in Experiment 1 to obtain the updated $X_ssh$ and $X_{mass}$. In this first experiment we assume these two process can be updated indepenently. 

```{r loadlibs, message = FALSE, warning = FALSE}
library(rgdal); library(sp);library(GEOmap)
library(INLA)
source("C:/ZSwork/glbm/BHM_sphere/functions.R")
source("C:/ZSwork/glbm/BHM_sphere/functions-barriers-dt-models-march2017.R")
```

# Update $X_{ssh}$

First we load the altimetry data and do some exploratory analysis on the spatial property of the process.

## Load data 

Load the pre-processed altimetry data. The data are the yearly trend estimates over 10 years (2005-2015) and their estimated errors at one degree resolution.
```{r alt_data}
library(ncdf4)
alt_nc <- nc_open("C:/ZSwork/glbm/Experiment2/trend_SSH_CCI_200501_201512.nc")
print(alt_nc)
lon <- ncvar_get(alt_nc, "lon")
lat <- ncvar_get(alt_nc, "lat")
trend_ssh <- ncvar_get(alt_nc, "trend_ssh") #note that there re NAs for land datat
err_ssh <- ncvar_get(alt_nc, "err")

alt_data <- data.frame(trend_ssh = as.numeric(trend_ssh), err_ssh = as.numeric(err_ssh))
alt_data$lon <- rep(lon, 180) 
alt_data$lat <- rep(lat, each = 360)
alt_data2 <- na.omit(alt_data)
## Find the xyz coords of the altimetry data
alt_loc <- do.call(cbind, Lll2xyz(lon = alt_data2$lon, lat = alt_data2$lat))
## plot the data
lattice::levelplot(trend_ssh ~ lon + lat, data = alt_data2, aspect = "iso",  at =seq(-20, 20, 4),
                     panel = function(x,y,z,...){
                       lattice::panel.levelplot(x,y,z,...)
                       map2 <- map("world2", interior = FALSE, plot = FALSE)
                       lattice::panel.xyplot(x=map2$x, y=map2$y, type = "l", col = "black")
                     },
                     main = title, xlab = "longitude", ylab = "latitude")

lattice::levelplot(err_ssh ~ lon + lat, data = alt_data2, aspect = "iso",  at = seq(0, 4, 0.5),
                     panel = function(x,y,z,...){
                       lattice::panel.levelplot(x,y,z,...)
                       map2 <- map("world2", interior = FALSE, plot = FALSE)
                       lattice::panel.xyplot(x=map2$x, y=map2$y, type = "l", col = "black")
                     },
                     main = title, xlab = "longitude", ylab = "latitude")
```

## prior set up

Now we do some exploratory analysis which will be helpful in setting up the prior for hyper parameters $\rho$ and $\sigma^2$ for the SSH process. We can set up a vague prior in this preliminary study and later on set the prior to be concertrated if more information of ssh is given. We learn a sensible value for a initial mean by plotting the variogram of the the altimetry data.

The following chunch plot the smoothed variogram of the altimerty trend. It takes a long time to run due to the size of the data.

```{r variogram, message = FALSE, eval = FALSE}
library(gstat)
coordinates(alt_data2) <- c("lon", "lat")
proj4string(alt_data2) <- CRS("+proj=longlat")
alt_datas <- alt_data2[sample(1:nrow(alt_data2), 5000),] # thin the data otherwise it takes too long! plot remains the same
v1 <- variogram(trend_ssh ~ 1, alt_datas) 
plot(v1)
```

From the variogram plot, it seems the correlation length is about 3000km and the variance can be as high as 25. Hence we set the prior mean of $\rho$ to $3000/6371 \approx 0.47$ and $\sigma= 5$.
```{r prior}
## Priors mean and variance for the parameters: rho and sigma
mu_r <- 3000/6371
v_r <- 1
mu_s <- 5
v_s <- 10^2
```

The sea surface height is only defined on oceans so we will model this process only on the ocean. The following chunk load the low resolution global ocean polygons from NatureEarth and generate mesh with equal area triangles of approximately one degree resolution.

## Generate mesh 

To build the spde model used for approximating the process, we need to generate a triagluar mesh for the process. In general, the triangles in the mesh should have similar size and shape and the size of the triangles should be no larger than the spatial correlation length. 

In our exploratory analysis, the correlation length is quite long, therefore we can choose a sparse mesh. Here we choose the triangle size to have approximately 5 degree resolution so that the edge length of the triangles are smaller than 500km on average which is much smaller than 3000km. 

The equal area triangles can be genrnated using fibonacci points. We will need about $360 \times 180/(5^2) = 2592 $ triangles and this corresponds to about 1037 vertices. In the following code, we tune the number of point so that the mesh have about 2600 triangles.

```{r ssh_mesh}
## Genereate Fibonacci points on the sphere
fibo_points <- fiboSphere(N = 650, L0 = TRUE)
fibo_points_xyz <- do.call(cbind, Lll2xyz(lat = fibo_points[,2], lon = fibo_points[,1]))
mesh0 <- inla.mesh.2d(loc = fibo_points_xyz, cutoff = 0.01, max.edge = 1)
```

Since the process is only defined on the ocean, we remove the mesh that are not in the modelling region. And to make sure the triangles capture the shape of the coastlines, we add extra points near the coastlines.
```{r ssh_mesh2}
## Load the Ocean polygon
Ocean <- readOGR(dsn = "Z:/WP1-BHM/maps/ne_110m_ocean", layer = "ne_110m_ocean")
plot(Ocean)

## Load coastline
Coastline <- readOGR(dsn = "Z:/WP1-BHM/maps/ne_110m_coastline", layer = "ne_110m_coastline")
## sample points along the coastlines for building up the mesh
CLpts <- spsample(Coastline, n =5000, type = "regular")
plot(CLpts)
coast_xyz <- do.call(cbind, Lll2xyz(lat = CLpts@coords[,2], lon = CLpts@coords[,1]))
## Now generate mesh with coast line added in
mesh1 <- inla.mesh.2d(loc = rbind(fibo_points_xyz, coast_xyz), cutoff = 0.01, max.edge = 1)
## Make this smoother
mesh1 <- inla.mesh.2d(loc = mesh1$loc, cutoff = 0.01, max.edge = 1)

## Remove mesh not in the ocean
mesh1 <- dt.mesh.addon.posTri(mesh = mesh1, globe = TRUE) 
Tlonlat <- Lxyz2ll(list(x = mesh1$posTri[,1], y = mesh1$posTri[,2], z = mesh1$posTri[,3]))
mesh1$Trill <- cbind(lon = Tlonlat$lon, lat =Tlonlat$lat)
TinOcean <- unlist(over(Ocean, SpatialPoints(coords=mesh1$Trill, proj4string = CRS(proj4string(Ocean))), returnList=T))
TAll <- 1:mesh1$t
ToutOcean <- TAll[-TinOcean]
Omega = dt.Omega(list(TinOcean, 1:mesh1$t), mesh1)

mesh_ssh <- mesh.sub(mesh1, Omega, 1)
summary(mesh_ssh)
```




```{r spde}
## Transform the parameters for the SPDE_GMRF approximation
trho <- Tlognorm(mu_r, v_r)
tsigma <- Tlognorm(mu_s, v_s)

## Build the SPDE model with the prior
lsigma0 <- tsigma[1]
theta1_s <- tsigma[2]
lrho0 <- trho[1]
theta2_s <- trho[2]
lkappa0 <- log(8)/2 - lrho0
ltau0 <- 0.5*log(1/(4*pi)) - lsigma0 - lkappa0

SSH_spde <- inla.spde2.matern(mesh_ssh, B.tau = matrix(c(ltau0, -1, 1),1,3), B.kappa = matrix(c(lkappa0, 0, -1), 1,3),
                              theta.prior.mean = c(0,0), theta.prior.prec = c(sqrt(1/theta1_s), sqrt(1/theta2_s)))

```





## Link data to process

Now we link the data to the process. The altimetry data is gridded with 1 degree resolution and we have a mesh with about the same resolution, so we can simply use a point to point identity map to link the data to the process: each data point observe the process from the same location.

```{r link_data}
## Link the process to observations and predictions
A_data <- inla.spde.make.A(mesh = mesh_ssh, loc = alt_loc)
A_pred <- inla.spde.make.A(mesh = mesh_ssh, loc = rbind(mesh_ssh$loc))

## Create the estimation and prediction stack
st.est <- inla.stack(data = list(y=alt_data2$trend_ssh), A = list(A_data),
                     effects = list(SSH = 1:SSH_spde$n.spde), tag = "est")
st.pred <- inla.stack(data = list(y=NA), A = list(A_pred),
                      effects = list(SSH=1:SSH_spde$n.spde), tag = "pred")
stSSH <- inla.stack(st.est, st.pred)
```

## INLA inference

Now we can run INLA for the Bayesian inference. Do not run on a desktop the process may use up to 25GB memory at peak. We ran this on a server with enough memory.

```{r inla_run, include = TRUE, eval = FALSE}
## Fix altimetry errors as they are known
hyper <- list(prec = list(fixed = TRUE, initial = 0))
prec_scale <- c(1/alt_data2$err_ssh^2, rep(1, nrow(A_pred)))

## The formular for modelling the SSH mean
formula = y ~ -1 +  f(SSH, model = SSH_spde)

## Run INLA
res_inla <- inla(formula, data = inla.stack.data(stSSH, spde = SSH_spde), family = "gaussian",
                 scale =prec_scale, control.family = list(hyper = hyper),
                 control.predictor=list(A=inla.stack.A(stSSH), compute =TRUE))
```

## Results

### Assemble and save results

Now assemble the inla inference and prediction results.
```{r inla_res, include = TRUE, cache=TRUE}
INLA_pred <- res_inla$summary.linear.predictor
## Extract and project predictions
pred_idx <- inla.stack.index(stSSH, tag = "pred")$data

## SSH
SSH_m <- INLA_pred$mean[pred_idx] 
SSH_u <- INLA_pred$sd[pred_idx]
proj <- inla.mesh.projector(mesh_ssh, projection = "longlat", dims = c(360,180), xlim = c(0.5,359.5), ylim = c(-89.5, 89.5))
SSH_grid <- expand.grid(proj$x, proj$y)
SSH_pred <- data.frame(lon = SSH_grid[,1], lat = SSH_grid[,2],
                       mean = as.vector(inla.mesh.project(proj, as.vector(SSH_m))),
                       u = as.vector(inla.mesh.project(proj, as.vector(SSH_u))))

ress <- list(res_inla = res_inla, spde = SSH_spde, st = stSSH, 
            mesh = mesh_ssh,  SSH_pred = SSH_pred)

save(ress, file ="/./projects/GlobalMass/WP1-BHM/Experiment2a/exp2a_ssh.RData")
```


### Plot the posteriors of the hyper parameters

```{r hyper, include=TRUE}
pars_SSH <- marginal_par(res = ress, process = "SSH", plot = TRUE)
## The posterior modes
print(paste("The estimated correlation lengths are:", pars_SSH$rho_mode*6371,  sep = "  "))

print(paste("The estimated marginal variances are:", pars_SSH$sigma_mode,sep = "  "))
```


## Plot the predictions

In this experiment, it is more convenient to produce the prediction at the altmetry data directly, since they are grid points.
We plot the predicted SSH at these locations and compare them to the altimetry data
```{r predict, include=TRUE}
alt_pred <- ress$SSH_pred
alt_pred$source1 <- "SSH predicted mean"
alt_pred$source2 <- "SSH predicted uncertainty"
alt_data$source1 <- "Altimetry trend"
alt_data$source2 <- "Altimetry error"
names(alt_data)[1:2] <- c("mean", "u") 
alt_diff <- data.frame(lon = alt_pred$lon, lat = alt_pred$lat, diff = alt_pred$mean-alt_data$mean)
alt_pred <- rbind(alt_pred, alt_data)


## plot the mean 
lattice::levelplot(mean ~ lon + lat | source1, data = alt_pred, aspect = "iso", at = seq(-20, 20, 2),
                     panel = function(x,y,z,...){
                       lattice::panel.levelplot(x,y,z,...)
                       map2 <- map("world2", interior = FALSE, plot = FALSE)
                       lattice::panel.xyplot(x=map2$x, y=map2$y, type = "l", col = "black")
                     },
                     main = title, xlab = "longitude", ylab = "latitude")

## plot the uncertainty
lattice::levelplot(u ~ lon + lat | source2, data = alt_pred, aspect = "iso", at = seq(0, 3, 0.5),
                     panel = function(x,y,z,...){
                       lattice::panel.levelplot(x,y,z,...)
                       map2 <- map("world2", interior = FALSE, plot = FALSE)
                       lattice::panel.xyplot(x=map2$x, y=map2$y, type = "l", col = "black")
                     },
                     main = title, xlab = "longitude", ylab = "latitude")

## Plot the differnce
lattice::levelplot(diff ~ lon + lat, data = alt_diff, aspect = "iso", at = seq(-20, 20, 2),
                     panel = function(x,y,z,...){
                       lattice::panel.levelplot(x,y,z,...)
                       map2 <- map("world2", interior = FALSE, plot = FALSE)
                       lattice::panel.xyplot(x=map2$x, y=map2$y, type = "l", col = "black")
                     },
                     main = title, xlab = "longitude", ylab = "latitude")
```





# Update $X_{mass}$

Now we do the same thing for the mass change process.

## Load data 

## prior set up

## Generate mesh 

We also need a mesh to represent the mass process. We could use the same as SSH but 




## Link data to process

## INLA inference

## Results




# Update $X_{steric}$

## Load GIA data

## Results